{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceBlend: Comparing Blending through Face-Swaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaimin Sanjay Gajjar (B20AI014)\n",
    "\n",
    "Sanidhya Sanjay Johri (B20CS061)\n",
    "\n",
    "Sawan Sanjay Patel (B20CS063)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "import logging\n",
    "import dlib\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Face detection\n",
    "def face_detection(img,upsample_times=1):\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    faces = detector(img, upsample_times)\n",
    "\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_PATH = './shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "## Face and points detection\n",
    "def face_points_detection(img, bbox:dlib.rectangle):\n",
    "    # Get the landmarks/parts for the face in box d.\n",
    "    shape = predictor(img, bbox)\n",
    "\n",
    "    # loop over the 68 facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y)-coordinates\n",
    "    coords = np.asarray(list([p.x, p.y] for p in shape.parts()), dtype=int)\n",
    "\n",
    "    # return the array of (x, y)-coordinates\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_face(im, r=10, choose=True):\n",
    "    faces = face_detection(im)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    if len(faces) == 1 or not choose:\n",
    "        idx = np.argmax([(face.right() - face.left()) * (face.bottom() - face.top()) for face in faces])\n",
    "        bbox = faces[idx]\n",
    "    else:\n",
    "        bbox = []\n",
    "\n",
    "        def click_on_face(event, x, y, flags, params):\n",
    "            if event != cv2.EVENT_LBUTTONDOWN:\n",
    "                return\n",
    "\n",
    "            for face in faces:\n",
    "                if face.left() < x < face.right() and face.top() < y < face.bottom():\n",
    "                    bbox.append(face)\n",
    "                    break\n",
    "\n",
    "        im_copy = im.copy()\n",
    "        for face in faces:\n",
    "            # draw the face bounding box\n",
    "            cv2.rectangle(im_copy, (face.left(), face.top()), (face.right(), face.bottom()), (0, 0, 255), 1)\n",
    "        cv2.imshow('Click the Face:', im_copy)\n",
    "        cv2.setMouseCallback('Click the Face:', click_on_face)\n",
    "        while len(bbox) == 0:\n",
    "            cv2.waitKey(1)\n",
    "        cv2.destroyAllWindows()\n",
    "        bbox = bbox[0]\n",
    "\n",
    "    points = np.asarray(face_points_detection(im, bbox))\n",
    "\n",
    "    im_w, im_h = im.shape[:2]\n",
    "    left, top = np.min(points, 0)\n",
    "    right, bottom = np.max(points, 0)\n",
    "\n",
    "    x, y = max(0, left - r), max(0, top - r)\n",
    "    w, h = min(right + r, im_h) - x, min(bottom + r, im_w) - y\n",
    "\n",
    "    return points - np.asarray([[x, y]]), (x, y, w, h), im[y:y + h, x:x + w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_all_faces(im, r=10):\n",
    "    faces = face_detection(im)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "\n",
    "    faceBoxes = {k : {\"points\" : None,\n",
    "                      \"shape\" : None,\n",
    "                      \"face\" : None} for k in range(len(faces))}\n",
    "    for i, bbox in enumerate(faces):\n",
    "        points = np.asarray(face_points_detection(im, bbox))\n",
    "\n",
    "        im_w, im_h = im.shape[:2]\n",
    "        left, top = np.min(points, 0)\n",
    "        right, bottom = np.max(points, 0)\n",
    "\n",
    "        x, y = max(0, left - r), max(0, top - r)\n",
    "        w, h = min(right + r, im_h) - x, min(bottom + r, im_w) - y\n",
    "        faceBoxes[i][\"points\"] = points - np.asarray([[x, y]])\n",
    "        faceBoxes[i][\"shape\"] = (x, y, w, h)\n",
    "        faceBoxes[i][\"face\"] = im[y:y + h, x:x + w]\n",
    "\n",
    "    return faceBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Transform\n",
    "def bilinear_interpolate(img, coords):\n",
    "    \"\"\" Interpolates over every image channel\n",
    "    http://en.wikipedia.org/wiki/Bilinear_interpolation\n",
    "    :param img: max 3 channel image\n",
    "    :param coords: 2 x _m_ array. 1st row = xcoords, 2nd row = ycoords\n",
    "    :returns: array of interpolated pixels with same shape as coords\n",
    "    \"\"\"\n",
    "    int_coords = np.int32(coords)\n",
    "    x0, y0 = int_coords\n",
    "    dx, dy = coords - int_coords\n",
    "\n",
    "    # 4 Neighour pixels\n",
    "    q11 = img[y0, x0]\n",
    "    q21 = img[y0, x0 + 1]\n",
    "    q12 = img[y0 + 1, x0]\n",
    "    q22 = img[y0 + 1, x0 + 1]\n",
    "\n",
    "    btm = q21.T * dx + q11.T * (1 - dx)\n",
    "    top = q22.T * dx + q12.T * (1 - dx)\n",
    "    inter_pixel = top * dy + btm * (1 - dy)\n",
    "\n",
    "    return inter_pixel.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_coordinates(points):\n",
    "    \"\"\" x,y grid coordinates within the ROI of supplied points\n",
    "    :param points: points to generate grid coordinates\n",
    "    :returns: array of (x, y) coordinates\n",
    "    \"\"\"\n",
    "    xmin = np.min(points[:, 0])\n",
    "    xmax = np.max(points[:, 0]) + 1\n",
    "    ymin = np.min(points[:, 1])\n",
    "    ymax = np.max(points[:, 1]) + 1\n",
    "\n",
    "    return np.asarray([(x, y) for y in range(ymin, ymax)\n",
    "                       for x in range(xmin, xmax)], np.uint32)\n",
    "\n",
    "\n",
    "def process_warp(src_img, result_img, tri_affines, dst_points, delaunay):\n",
    "    \"\"\"\n",
    "    Warp each triangle from the src_image only within the\n",
    "    ROI of the destination image (points in dst_points).\n",
    "    \"\"\"\n",
    "    roi_coords = grid_coordinates(dst_points)\n",
    "    # indices to vertices. -1 if pixel is not in any triangle\n",
    "    roi_tri_indices = delaunay.find_simplex(roi_coords)\n",
    "\n",
    "    for simplex_index in range(len(delaunay.simplices)):\n",
    "        coords = roi_coords[roi_tri_indices == simplex_index]\n",
    "        num_coords = len(coords)\n",
    "        out_coords = np.dot(tri_affines[simplex_index],\n",
    "                            np.vstack((coords.T, np.ones(num_coords))))\n",
    "        x, y = coords.T\n",
    "        result_img[y, x] = bilinear_interpolate(src_img, out_coords)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular_affine_matrices(vertices, src_points, dst_points):\n",
    "    \"\"\"\n",
    "    Calculate the affine transformation matrix for each\n",
    "    triangle (x,y) vertex from dst_points to src_points\n",
    "    :param vertices: array of triplet indices to corners of triangle\n",
    "    :param src_points: array of [x, y] points to landmarks for source image\n",
    "    :param dst_points: array of [x, y] points to landmarks for destination image\n",
    "    :returns: 2 x 3 affine matrix transformation for a triangle\n",
    "    \"\"\"\n",
    "    ones = [1, 1, 1]\n",
    "    for tri_indices in vertices:\n",
    "        src_tri = np.vstack((src_points[tri_indices, :].T, ones))\n",
    "        dst_tri = np.vstack((dst_points[tri_indices, :].T, ones))\n",
    "        mat = np.dot(src_tri, np.linalg.inv(dst_tri))[:2, :]\n",
    "        yield mat\n",
    "\n",
    "\n",
    "def warp_image_3d(src_img, src_points, dst_points, dst_shape, dtype=np.uint8):\n",
    "    rows, cols = dst_shape[:2]\n",
    "    result_img = np.zeros((rows, cols, 3), dtype=dtype)\n",
    "\n",
    "    delaunay = spatial.Delaunay(dst_points)\n",
    "    tri_affines = np.asarray(list(triangular_affine_matrices(\n",
    "        delaunay.simplices, src_points, dst_points)))\n",
    "\n",
    "    process_warp(src_img, result_img, tri_affines, dst_points, delaunay)\n",
    "\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_from_points(points1, points2):\n",
    "    points1 = points1.astype(np.float64)\n",
    "    points2 = points2.astype(np.float64)\n",
    "\n",
    "    c1 = np.mean(points1, axis=0)\n",
    "    c2 = np.mean(points2, axis=0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "\n",
    "    s1 = np.std(points1)\n",
    "    s2 = np.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(np.dot(points1.T, points2))\n",
    "    R = (np.dot(U, Vt)).T\n",
    "\n",
    "    return np.vstack([np.hstack([s2 / s1 * R,\n",
    "                                (c2.T - np.dot(s2 / s1 * R, c1.T))[:, np.newaxis]]),\n",
    "                      np.array([[0., 0., 1.]])])\n",
    "\n",
    "\n",
    "def warp_image_2d(im, M, dshape):\n",
    "    output_im = np.zeros(dshape, dtype=im.dtype)\n",
    "    cv2.warpAffine(im,\n",
    "                   M[:2],\n",
    "                   (dshape[1], dshape[0]),\n",
    "                   dst=output_im,\n",
    "                   borderMode=cv2.BORDER_TRANSPARENT,\n",
    "                   flags=cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "    return output_im\n",
    "\n",
    "\n",
    "## Generate Mask\n",
    "def mask_from_points(size, points,erode_flag=1):\n",
    "    radius = 10  # kernel size\n",
    "    kernel = np.ones((radius, radius), np.uint8)\n",
    "\n",
    "    mask = np.zeros(size, np.uint8)\n",
    "    cv2.fillConvexPoly(mask, cv2.convexHull(points), 255)\n",
    "    if erode_flag:\n",
    "        mask = cv2.erode(mask, kernel,iterations=1)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color Correction\n",
    "def correct_colours(im1, im2, landmarks1):\n",
    "    COLOUR_CORRECT_BLUR_FRAC = 0.75\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "\n",
    "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * np.linalg.norm(\n",
    "                              np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
    "                              np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
    "\n",
    "    # Avoid divide-by-zero errors.\n",
    "    im2_blur = im2_blur.astype(int)\n",
    "    im2_blur += 128*(im2_blur <= 1)\n",
    "\n",
    "    result = im2.astype(np.float64) * im1_blur.astype(np.float64) / im2_blur.astype(np.float64)\n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "## Copy-and-paste\n",
    "def apply_mask(img, mask):\n",
    "    \"\"\" Apply mask to supplied image\n",
    "    :param img: max 3 channel image\n",
    "    :param mask: [0-255] values in mask\n",
    "    :returns: new image with mask applied\n",
    "    \"\"\"\n",
    "    masked_img=cv2.bitwise_and(img,img,mask=mask)\n",
    "\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alpha blending\n",
    "def alpha_feathering(src_img, dest_img, img_mask, blur_radius=15):\n",
    "    mask = cv2.blur(img_mask, (blur_radius, blur_radius))\n",
    "    mask = mask / 255.0\n",
    "\n",
    "    result_img = np.empty(src_img.shape, np.uint8)\n",
    "    for i in range(3):\n",
    "        result_img[..., i] = src_img[..., i] * mask + dest_img[..., i] * (1-mask)\n",
    "\n",
    "    return result_img\n",
    "\n",
    "\n",
    "def check_points(img,points):\n",
    "    # Todo: I just consider one situation.\n",
    "    if points[8,1]>img.shape[0]:\n",
    "        logging.error(\"Jaw part out of image\")\n",
    "    else:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_swap(src_face, dst_face, src_points, dst_points, dst_shape, dst_img, correct_color, warp_2d, end=48):\n",
    "    h, w = dst_face.shape[:2]\n",
    "\n",
    "    ## 3d warp\n",
    "    warped_src_face = warp_image_3d(src_face, src_points[:end], dst_points[:end], (h, w))\n",
    "    ## Mask for blending\n",
    "    mask = mask_from_points((h, w), dst_points)\n",
    "    mask_src = np.mean(warped_src_face, axis=2) > 0\n",
    "    mask = np.asarray(mask * mask_src, dtype=np.uint8)\n",
    "    ## Correct color\n",
    "    if correct_color:\n",
    "        warped_src_face = apply_mask(warped_src_face, mask)\n",
    "        dst_face_masked = apply_mask(dst_face, mask)\n",
    "        warped_src_face = correct_colours(dst_face_masked, warped_src_face, dst_points)\n",
    "    ## 2d warp\n",
    "    if warp_2d:\n",
    "        unwarped_src_face = warp_image_3d(warped_src_face, dst_points[:end], src_points[:end], src_face.shape[:2])\n",
    "        warped_src_face = warp_image_2d(unwarped_src_face, transformation_from_points(dst_points, src_points),\n",
    "                                        (h, w, 3))\n",
    "\n",
    "        mask = mask_from_points((h, w), dst_points)\n",
    "        mask_src = np.mean(warped_src_face, axis=2) > 0\n",
    "        mask = np.asarray(mask * mask_src, dtype=np.uint8)\n",
    "\n",
    "    ## Shrink the mask\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    ##Poisson Blending\n",
    "    r = cv2.boundingRect(mask)\n",
    "    center = ((r[0] + int(r[2] / 2), r[1] + int(r[3] / 2)))\n",
    "    output = alpha_feathering(warped_src_face, dst_face, mask)\n",
    "\n",
    "    x, y, w, h = dst_shape\n",
    "    dst_img_cp = dst_img.copy()\n",
    "    dst_img_cp[y:y + h, x:x + w] = output\n",
    "\n",
    "    return dst_img_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read images\n",
    "src = \"inputs/jaimin.jpeg\"\n",
    "dst = \"inputs/sawan.jpeg\"\n",
    "out = \"outputs/alpha/jaimin-sawan.jpeg\"\n",
    "correct_color = \"\"\n",
    "warp_2d = \"\"\n",
    "\n",
    "src_img = cv2.imread(src)\n",
    "dst_img = cv2.imread(dst)\n",
    "\n",
    "# Select src face\n",
    "src_points, src_shape, src_face = select_face(src_img)\n",
    "# Select dst face\n",
    "dst_faceBoxes = select_all_faces(dst_img)\n",
    "\n",
    "if dst_faceBoxes is None:\n",
    "    print('Detect 0 Face !!!')\n",
    "    exit(-1)\n",
    "\n",
    "output = dst_img\n",
    "for k, dst_face in dst_faceBoxes.items():\n",
    "    output = face_swap(src_face, dst_face[\"face\"], src_points,\n",
    "                        dst_face[\"points\"], dst_face[\"shape\"],\n",
    "                        output, correct_color, warp_2d)\n",
    "\n",
    "dir_path = os.path.dirname(out)\n",
    "if not os.path.isdir(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "cv2.imwrite(out, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
